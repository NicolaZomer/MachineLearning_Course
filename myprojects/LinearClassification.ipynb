{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification and Linear Predictors\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification: Perceptron algorithm\n",
    "\n",
    "In the next code cell I realized the Perceptron algorithm (for halfspaces) \n",
    "- $\\mathbf{x}\\in\\mathbb{R}^d$: for each sample is a vector of features (_input_)\n",
    "- $\\mathbf{x'}\\in \\mathbb{R}^{d+1}$ using homogeneous coordinates: \n",
    "    $$\n",
    "    \\mathbf{x}\\rightarrow \\mathbf{x'} = (1, \\mathbf{x})\n",
    "    $$\n",
    "- $\\mathbf{y} = \\{-1, 1\\}$ in the case of binary classification (_output_) $\\rightarrow$ 0-1 loss \n",
    "- $\\mathbf{w}$: weights vector ($b$: bias) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You haven't specified the maximum number of cicles. Risk of having an infinite loop if the data are not linearly separable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-2,  3, -4,  3]), 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def perceptron(S, maxcycles=None, lam = 1 , w=None):\n",
    "    # S is the training set: (x1, y1), ..., (x_m, y_m) given as an array of 2 list: (xvec, yvec)\n",
    "    # maxcycles is the maximum number of cicles that the algorithm can make (to avoid infinit loop)\n",
    "    # w is the initial solution, it is an optional argument. It is w' for the homogeneous linear function: w'=(b, w)\n",
    "    \n",
    "    if maxcycles == None:\n",
    "        print(\"You haven't specified the maximum number of cicles. Risk of having an infinite loop if the data are not linearly separable.\")\n",
    "    \n",
    "    x = S[0]\n",
    "    y = S[1]\n",
    "    # print('x:', x, '\\ny:', y)\n",
    "    \n",
    "    m = len(S[0])\n",
    "    f = len(x[0])+1   # number of features (+1 for homogeneous coordinates)\n",
    "    \n",
    "    xprime = np.zeros((m, f), dtype='int')\n",
    "\n",
    "    for i in range(m):\n",
    "        xprime[i, 0] = 1\n",
    "        xprime[i, 1:] = x[i]\n",
    "    x = xprime\n",
    "    # print(\"x':\", x)\n",
    "    \n",
    "    if w is None: w = np.zeros(f, dtype='int')  \n",
    "    \n",
    "    # perceptron algorithm\n",
    "    exist_misclassified = True\n",
    "    loop_check = 0\n",
    "    \n",
    "    while exist_misclassified == True:\n",
    "        loop_check +=1 \n",
    "        \n",
    "        wrong_samples = []\n",
    "        for i in range(m):\n",
    "            if y[i]*np.dot(w, x[i]) <= 0:\n",
    "                wrong_samples.append(i)\n",
    "                \n",
    "        # check if wrong_samples is empty (if it's empty calling it return false)\n",
    "        if not wrong_samples:   \n",
    "            exist_misclassified = False\n",
    "        else: \n",
    "            selected_i = random.choice(wrong_samples)\n",
    "            w = w+lam*y[selected_i]*x[selected_i]\n",
    "        \n",
    "        if maxcycles is not None and loop_check > maxcycles:\n",
    "            # compute 0-1 Loss:\n",
    "            Loss = len(wrong_samples)/m\n",
    "            print('Excedeed maximum number of cycles allowed')\n",
    "            return w, Loss\n",
    "    \n",
    "    return w, 0        \n",
    "\n",
    "xtrain = np.array([[1, 2, 3], [0, 2, 2], [0, 2, 0], [0, 2, 2]])\n",
    "ytrain = np.array([1, -1, -1, -1])\n",
    "trainSet = [xtrain, ytrain]\n",
    "\n",
    "perceptron(trainSet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the perceptron function I get the weights vector $w'=(b, w)$ in homogeneous coordinates. I could print the data and the separating hyperplane (in the 2D and 3D cases), to have a graphic representation of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification with Logistic Regression\n",
    "> There is a Logistic regression function from Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression: Least Squares algorithm\n",
    "\n",
    "Now I realize, in the next code cell, there is Least Squares algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leastSquares(S):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56cee935aa9a3f3637f03175b8d659cf88f72e32c50a44ffefdb433a8a4e1922"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
